No.:0
sentence: Hi, Iam 34years old & my sonography says Solid cystic complex cyst noted in 6 o clock position in retroareolar region in left breast measuring 19*18mm & left axillary lymphadenopathy.
input_ids:[101, 8790, 117, 146, 2312, 3236, 4980, 7666, 1385, 111, 1139, 1488, 9543, 1867, 20375, 172, 6834, 2941, 2703, 172, 6834, 1204, 2382, 1107, 127, 184, 4705, 1700, 1107, 1231, 8005, 8836, 21459, 1805, 1107, 1286, 7209, 10099, 1627, 115, 1407, 6262, 111, 1286, 170, 8745, 12576, 1183, 181, 25698, 6397, 2728, 12233, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0]
attention_masks:[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]
segment_ids:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]


No.:0
sentence: hi, my doctor has come to the conclusion i have IBS after not showing any signs of chrons in a colonoscopy test.
input_ids:[101, 20844, 117, 1139, 3995, 1144, 1435, 1106, 1103, 6593, 178, 1138, 146, 9782, 1170, 1136, 4000, 1251, 5300, 1104, 22572, 19298, 1107, 170, 1884, 4934, 2155, 20739, 2774, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
attention_masks:[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
segment_ids:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]


No.:0
sentence: I have been a coffee drinker on and off since I was little.
input_ids:[101, 146, 1138, 1151, 170, 3538, 3668, 1200, 1113, 1105, 1228, 1290, 146, 1108, 1376, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
attention_masks:[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
segment_ids:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]


No.:0
sentence: hi, my doctor has come to the conclusion i have IBS after not showing any signs of chrons in a colonoscopy test.
input_ids:[101, 20844, 117, 1139, 3995, 1144, 1435, 1106, 1103, 6593, 178, 1138, 146, 9782, 1170, 1136, 4000, 1251, 5300, 1104, 22572, 19298, 1107, 170, 1884, 4934, 2155, 20739, 2774, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
attention_masks:[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
segment_ids:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]


No.:0
sentence: Hi, Iam 34years old & my sonography says Solid cystic complex cyst noted in 6 o clock position in retroareolar region in left breast measuring 19*18mm & left axillary lymphadenopathy.
input_ids:[101, 8790, 117, 146, 2312, 3236, 4980, 7666, 1385, 111, 1139, 1488, 9543, 1867, 20375, 172, 6834, 2941, 2703, 172, 6834, 1204, 2382, 1107, 127, 184, 4705, 1700, 1107, 1231, 8005, 8836, 21459, 1805, 1107, 1286, 7209, 10099, 1627, 115, 1407, 6262, 111, 1286, 170, 8745, 12576, 1183, 181, 25698, 6397, 2728, 12233, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0]
attention_masks:[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]
segment_ids:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]


No.:0
sentence: I have been a coffee drinker on and off since I was little.
input_ids:[101, 146, 1138, 1151, 170, 3538, 3668, 1200, 1113, 1105, 1228, 1290, 146, 1108, 1376, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
attention_masks:[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
segment_ids:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]


======== Train Datasets: HIF2016_DIS00_polarity.tsv HIF2016_DIS01_polarity.tsv
======== Test Dataset: HIF2016_DIS02_polarity.tsv
========== Running training ==========
  Num examples = 2583
  Batch size = 32
  Num steps = 405
Train loss: 1.0249713085591794
Train loss: 0.7185354933142662
Train loss: 0.5453258145600557
Train loss: 0.46035573035478594
Train loss: 0.40483582094311715
========== Running evaluation ==========
  Num examples =864
  Batch size = 32
========== Test results ==========
  eval_accuracy = 0.7442129629629629
  eval_loss = 0.6550003510934336
  loss = 0.40483582094311715
              precision    recall  f1-score   support

           0       0.80      0.64      0.71       171
           1       0.76      0.83      0.79       477
           2       0.68      0.64      0.66       216

   micro avg       0.74      0.74      0.74       864
   macro avg       0.74      0.70      0.72       864
weighted avg       0.74      0.74      0.74       864



len pred:  864
len true:  864
len sen:  864
======== Train Datasets: HIF2016_DIS02_polarity.tsv HIF2016_DIS01_polarity.tsv
======== Test Dataset: HIF2016_DIS00_polarity.tsv
========== Running training ==========
  Num examples = 2492
  Batch size = 32
  Num steps = 390
Train loss: 0.9602490624824127
Train loss: 0.7785107524364026
Train loss: 0.5971153428802243
Train loss: 0.5007173626066802
Train loss: 0.5004908423145096
========== Running evaluation ==========
  Num examples =955
  Batch size = 32
========== Test results ==========
  eval_accuracy = 0.7361256544502618
  eval_loss = 0.6522483646869659
  loss = 0.5004908423145096
              precision    recall  f1-score   support

           0       0.72      0.69      0.71       162
           1       0.79      0.76      0.77       499
           2       0.66      0.72      0.69       294

   micro avg       0.74      0.74      0.74       955
   macro avg       0.72      0.72      0.72       955
weighted avg       0.74      0.74      0.74       955



len pred:  1819
len true:  1819
len sen:  1819
======== Train Datasets: HIF2016_DIS02_polarity.tsv HIF2016_DIS00_polarity.tsv
======== Test Dataset: HIF2016_DIS01_polarity.tsv
========== Running training ==========
  Num examples = 1819
  Batch size = 32
  Num steps = 285
Train loss: 0.986220226756164
Train loss: 0.734974375792912
Train loss: 0.5671265880976405
Train loss: 0.4677009526640177
Train loss: 0.3850152968828167
========== Running evaluation ==========
  Num examples =1628
  Batch size = 32
========== Test results ==========
  eval_accuracy = 0.7438574938574939
  eval_loss = 0.6853175899561714
  loss = 0.3850152968828167
              precision    recall  f1-score   support

           0       0.74      0.67      0.70       302
           1       0.71      0.84      0.77       712
           2       0.79      0.67      0.73       614

   micro avg       0.74      0.74      0.74      1628
   macro avg       0.75      0.73      0.73      1628
weighted avg       0.75      0.74      0.74      1628



len pred:  3447
len true:  3447
len sen:  3447
======== Train Datasets: HIF2016_DIS02_factuality.tsv HIF2016_DIS00_factuality.tsv
======== Test Dataset: HIF2016_DIS01_factuality.tsv
========== Running training ==========
  Num examples = 1699
  Batch size = 32
  Num steps = 270
Train loss: 1.003237397040961
Train loss: 0.7969299138716932
Train loss: 0.679723432603872
Train loss: 0.5840516287200855
Train loss: 0.5358952013951428
========== Running evaluation ==========
  Num examples =1593
  Batch size = 32
========== Test results ==========
  eval_accuracy = 0.7765222849968613
  eval_loss = 0.5786199241876602
  loss = 0.5358952013951428
              precision    recall  f1-score   support

           0       0.85      0.92      0.89       931
           1       0.84      0.53      0.65       389
           2       0.50      0.62      0.55       273

   micro avg       0.78      0.78      0.78      1593
   macro avg       0.73      0.69      0.70      1593
weighted avg       0.79      0.78      0.77      1593



len pred:  1593
len true:  1593
len sen:  1593
======== Train Datasets: HIF2016_DIS01_factuality.tsv HIF2016_DIS00_factuality.tsv
======== Test Dataset: HIF2016_DIS02_factuality.tsv
========== Running training ==========
  Num examples = 2479
  Batch size = 32
  Num steps = 390
Train loss: 0.9555660695224614
Train loss: 0.6809886639768427
Train loss: 0.5459839339767184
Train loss: 0.4550208068126208
Train loss: 0.40957024654784757
========== Running evaluation ==========
  Num examples =813
  Batch size = 32
========== Test results ==========
  eval_accuracy = 0.7601476014760148
  eval_loss = 0.6251596957445145
  loss = 0.40957024654784757
              precision    recall  f1-score   support

           0       0.81      0.82      0.81       278
           1       0.76      0.78      0.77       310
           2       0.69      0.66      0.68       225

   micro avg       0.76      0.76      0.76       813
   macro avg       0.75      0.75      0.75       813
weighted avg       0.76      0.76      0.76       813



len pred:  2406
len true:  2406
len sen:  2406
======== Train Datasets: HIF2016_DIS01_factuality.tsv HIF2016_DIS02_factuality.tsv
======== Test Dataset: HIF2016_DIS00_factuality.tsv
========== Running training ==========
  Num examples = 2406
  Batch size = 32
  Num steps = 380
Train loss: 0.956912236213684
Train loss: 0.6308789690335591
Train loss: 0.5030753501256306
Train loss: 0.4274309625228246
Train loss: 0.3931554845968882
========== Running evaluation ==========
  Num examples =886
  Batch size = 32
========== Test results ==========
  eval_accuracy = 0.6828442437923251
  eval_loss = 0.8300397736685616
  loss = 0.3931554845968882
              precision    recall  f1-score   support

           0       0.68      0.89      0.77       348
           1       0.73      0.62      0.67       271
           2       0.65      0.49      0.56       267

   micro avg       0.68      0.68      0.68       886
   macro avg       0.68      0.66      0.66       886
weighted avg       0.68      0.68      0.67       886



len pred:  3292
len true:  3292
len sen:  3292
